{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-33ab8e96b432>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mlocal_device_protos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocal_device_protos\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'GPU'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mget_available_gpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-33ab8e96b432>\u001b[0m in \u001b[0;36mget_available_gpus\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_available_gpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mlocal_device_protos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocal_device_protos\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'GPU'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/reactlover_eiei/downloads/.bashrc/lib/python3.5/site-packages/tensorflow/python/client/device_lib.py\u001b[0m in \u001b[0;36mlist_local_devices\u001b[1;34m(session_config)\u001b[0m\n\u001b[0;32m     39\u001b[0m   return [\n\u001b[0;32m     40\u001b[0m       \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m   ]\n",
      "\u001b[1;32m/home/reactlover_eiei/downloads/.bashrc/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mlist_devices\u001b[1;34m(session_config)\u001b[0m\n\u001b[0;32m   1677\u001b[0m                                           status)\n\u001b[0;32m   1678\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1679\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mListDevices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/reactlover_eiei/downloads/.bashrc/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "from data_sampling import verify_samples\n",
    "import pandas as pd\n",
    "\n",
    "#verify_samples()\n",
    "\n",
    "batch_size = 4096\n",
    "STROKE_COUNT = 196\n",
    "TRAIN_SAMPLES = 750\n",
    "VALID_SAMPLES = 75\n",
    "TEST_SAMPLES = 50\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "def get_available_gpus():\n",
    "    from tensorflow.python.client import device_lib\n",
    "    return device_lib.list_local_devices()\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "def top_3_accuracy(x,y): return top_k_categorical_accuracy(x,y, 3)\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from glob import glob\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "*FILES, = filter(lambda x:x[0]!='.',os.listdir('train_sampled'))\n",
    "COL_NAMES = ['countrycode', 'drawing', 'key_id', 'recognized', 'timestamp', 'word']\n",
    "\n",
    "def _stack_it(raw_strokes):\n",
    "    stroke_vec = literal_eval(raw_strokes) # string->list\n",
    "    in_strokes = [(xi,yi,i)  \n",
    "     for i,(x,y) in enumerate(stroke_vec) \n",
    "     for xi,yi in zip(x,y)]\n",
    "    c_strokes = np.stack(in_strokes)\n",
    "    c_strokes[:,2] = [1]+np.diff(c_strokes[:,2]).tolist()\n",
    "    c_strokes[:,2] += 1\n",
    "    return pad_sequences(c_strokes.swapaxes(0, 1), \n",
    "                         maxlen=STROKE_COUNT, \n",
    "                         padding='post').swapaxes(0, 1)\n",
    "\n",
    "def read_batch(base, files):\n",
    "    out_df_list = []\n",
    "    for c_path in files:\n",
    "        c_path = os.path.join(base, c_path)\n",
    "        c_df = pd.read_csv(c_path, engine='python')\n",
    "        c_df.columns=COL_NAMES\n",
    "        out_df_list += [c_df[['drawing', 'word']]]\n",
    "    full_df = pd.concat(out_df_list)\n",
    "    full_df['drawing'] = full_df['drawing'].\\\n",
    "        map(_stack_it)\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = read_batch('train_sampled',FILES)\n",
    "valid_df = read_batch('valid_sampled',FILES)\n",
    "test_df = read_batch('test_sampled',FILES)\n",
    "word_encoder = LabelEncoder()\n",
    "word_encoder.fit(train_df['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 196, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_Xy(in_df):\n",
    "    X = np.stack(in_df['drawing'], 0)\n",
    "    y = to_categorical(word_encoder.transform(in_df['word'].values))\n",
    "    return X, y\n",
    "train_X, train_y = get_Xy(train_df)\n",
    "valid_X, valid_y = get_Xy(valid_df)\n",
    "test_X, test_y = get_Xy(test_df)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, None, 3)           12        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 64)          17408     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 92,784\n",
      "Trainable params: 92,778\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv1D, LSTM, Dense, Dropout\n",
    "stroke_read_model = Sequential()\n",
    "stroke_read_model.add(BatchNormalization(input_shape = (None,)+train_X.shape[2:]))\n",
    "# filter count and length are taken from the script https://github.com/tensorflow/models/blob/master/tutorials/rnn/quickdraw/train_model.py\n",
    "# stroke_read_model.add(Conv1D(48, (5,)))\n",
    "# stroke_read_model.add(Dropout(0.3))\n",
    "# stroke_read_model.add(Conv1D(64, (5,)))\n",
    "# stroke_read_model.add(Dropout(0.3))\n",
    "# stroke_read_model.add(Conv1D(96, (3,)))\n",
    "# stroke_read_model.add(Dropout(0.3))\n",
    "stroke_read_model.add(LSTM(64, return_sequences = True))\n",
    "stroke_read_model.add(Dropout(0.3))\n",
    "stroke_read_model.add(LSTM(64, return_sequences = False))\n",
    "stroke_read_model.add(Dropout(0.3))\n",
    "stroke_read_model.add(Dense(256))\n",
    "stroke_read_model.add(Dropout(0.3))\n",
    "stroke_read_model.add(Dense(len(word_encoder.classes_), activation = 'softmax'))\n",
    "stroke_read_model.compile(optimizer = 'adam', \n",
    "                          loss = 'categorical_crossentropy', \n",
    "                          metrics = ['categorical_accuracy', top_3_accuracy])\n",
    "stroke_read_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_path=\"{}_weights.best.hdf5\".format('stroke_lstm_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, \n",
    "                                   verbose=1, mode='auto', min_delta=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=5) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished with 399.3058400154114 second(s)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "t_start = time.time()\n",
    "stroke_read_model.fit(train_X, train_y,\n",
    "                      validation_data = (valid_X, valid_y), \n",
    "                      batch_size = batch_size,\n",
    "                      epochs = 1,\n",
    "                      callbacks = callbacks_list)\n",
    "clear_output()\n",
    "t_end = time.time()\n",
    "print('Train finished with',t_end-t_start,'second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 13s 1ms/step\n",
      "Accuracy: 1.1%, Top 3 Accuracy 3.2%\n"
     ]
    }
   ],
   "source": [
    "stroke_read_model.load_weights(weight_path)\n",
    "lstm_results = stroke_read_model.evaluate(test_X, test_y, batch_size = 4096)\n",
    "print('Accuracy: %2.1f%%, Top 3 Accuracy %2.1f%%' % (100*lstm_results[1], 100*lstm_results[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        airplane       0.00      0.00      0.00       100\n",
      "     alarm clock       0.00      0.00      0.00       100\n",
      "       ambulance       0.00      0.00      0.00       100\n",
      "           angel       0.00      0.00      0.00       100\n",
      "animal migration       0.00      0.00      0.00       100\n",
      "             ant       0.00      0.00      0.00       100\n",
      "           anvil       0.00      0.00      0.00       100\n",
      "           apple       0.00      0.00      0.00       100\n",
      "             arm       0.00      0.00      0.00       100\n",
      "       asparagus       0.00      0.00      0.00       100\n",
      "             axe       0.00      0.00      0.00       100\n",
      "        backpack       0.00      0.00      0.00       100\n",
      "          banana       0.00      0.00      0.00       100\n",
      "         bandage       0.00      0.00      0.00       100\n",
      "            barn       0.00      0.00      0.00       100\n",
      "        baseball       0.00      0.00      0.00       100\n",
      "    baseball bat       0.00      0.00      0.00       100\n",
      "          basket       0.00      0.00      0.00       100\n",
      "      basketball       0.00      0.00      0.00       100\n",
      "             bat       0.00      0.00      0.00       100\n",
      "         bathtub       0.00      0.00      0.00       100\n",
      "           beach       0.00      0.00      0.00       100\n",
      "            bear       0.00      0.00      0.00       100\n",
      "           beard       0.00      0.00      0.00       100\n",
      "             bed       0.00      0.00      0.00       100\n",
      "             bee       0.00      0.00      0.00       100\n",
      "            belt       0.00      0.00      0.00       100\n",
      "           bench       0.00      0.00      0.00       100\n",
      "         bicycle       0.00      0.00      0.00       100\n",
      "      binoculars       0.00      0.00      0.00       100\n",
      "            bird       0.00      0.00      0.00       100\n",
      "   birthday cake       0.00      0.00      0.00       100\n",
      "      blackberry       0.20      0.11      0.14       100\n",
      "       blueberry       0.00      0.00      0.00       100\n",
      "            book       0.00      0.00      0.00       100\n",
      "       boomerang       0.00      0.00      0.00       100\n",
      "       bottlecap       0.00      0.00      0.00       100\n",
      "          bowtie       0.00      0.00      0.00       100\n",
      "        bracelet       0.00      0.00      0.00       100\n",
      "           brain       0.00      0.00      0.00       100\n",
      "           bread       0.00      0.00      0.00       100\n",
      "          bridge       0.00      0.00      0.00       100\n",
      "        broccoli       0.00      0.00      0.00       100\n",
      "           broom       0.00      0.00      0.00       100\n",
      "          bucket       0.00      0.00      0.00       100\n",
      "       bulldozer       0.00      0.00      0.00       100\n",
      "             bus       0.00      0.00      0.00       100\n",
      "            bush       0.00      0.00      0.00       100\n",
      "       butterfly       0.00      0.00      0.00       100\n",
      "          cactus       0.00      0.00      0.00       100\n",
      "            cake       0.00      0.00      0.00       100\n",
      "      calculator       0.00      0.00      0.00       100\n",
      "        calendar       0.00      0.00      0.00       100\n",
      "           camel       0.00      0.00      0.00       100\n",
      "          camera       0.00      0.00      0.00       100\n",
      "      camouflage       0.00      0.00      0.00       100\n",
      "        campfire       0.00      0.00      0.00       100\n",
      "          candle       0.00      0.00      0.00       100\n",
      "          cannon       0.00      0.00      0.00       100\n",
      "           canoe       0.00      0.00      0.00       100\n",
      "             car       0.00      0.00      0.00       100\n",
      "          carrot       0.00      0.00      0.00       100\n",
      "          castle       0.00      0.00      0.00       100\n",
      "             cat       0.00      0.00      0.00       100\n",
      "     ceiling fan       0.00      0.00      0.00       100\n",
      "      cell phone       0.00      0.00      0.00       100\n",
      "           cello       0.00      0.00      0.00       100\n",
      "           chair       0.00      0.00      0.00       100\n",
      "      chandelier       0.00      0.00      0.00       100\n",
      "          church       0.00      0.00      0.00       100\n",
      "          circle       0.00      0.00      0.00       100\n",
      "        clarinet       0.00      0.00      0.00       100\n",
      "           clock       0.00      0.00      0.00       100\n",
      "           cloud       0.00      0.00      0.00       100\n",
      "      coffee cup       0.00      0.00      0.00       100\n",
      "         compass       0.00      0.00      0.00       100\n",
      "        computer       0.00      0.00      0.00       100\n",
      "          cookie       0.00      0.00      0.00       100\n",
      "          cooler       0.00      0.00      0.00       100\n",
      "           couch       0.00      0.00      0.00       100\n",
      "             cow       0.00      0.00      0.00       100\n",
      "            crab       0.00      0.00      0.00       100\n",
      "          crayon       0.00      0.00      0.00       100\n",
      "       crocodile       0.00      0.00      0.00       100\n",
      "           crown       0.00      0.00      0.00       100\n",
      "     cruise ship       0.00      0.00      0.00       100\n",
      "             cup       0.00      0.00      0.00       100\n",
      "         diamond       0.00      0.00      0.00       100\n",
      "      dishwasher       0.00      0.00      0.00       100\n",
      "    diving board       0.00      0.00      0.00       100\n",
      "             dog       0.00      0.00      0.00       100\n",
      "         dolphin       0.00      0.00      0.00       100\n",
      "           donut       0.00      0.00      0.00       100\n",
      "            door       0.00      0.00      0.00       100\n",
      "          dragon       0.01      1.00      0.02       100\n",
      "         dresser       0.00      0.00      0.00       100\n",
      "           drill       0.00      0.00      0.00       100\n",
      "           drums       0.00      0.00      0.00       100\n",
      "            duck       0.00      0.00      0.00       100\n",
      "        dumbbell       0.00      0.00      0.00       100\n",
      "\n",
      "       micro avg       0.01      0.01      0.01     10000\n",
      "       macro avg       0.00      0.01      0.00     10000\n",
      "    weighted avg       0.00      0.01      0.00     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reactlover_eiei/downloads/.bashrc/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4efad10630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "test_cat = np.argmax(test_y, 1)\n",
    "pred_y = stroke_read_model.predict(test_X, batch_size = 4096)\n",
    "pred_cat = np.argmax(pred_y, 1)\n",
    "plt.matshow(confusion_matrix(test_cat, pred_cat))\n",
    "print(classification_report(test_cat, pred_cat, \n",
    "                            target_names = [x for x in word_encoder.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
